<div align="center">
  <p>
    <a href="https://www.paypal.com/cgi-bin/webscr?cmd=_donations&business=NF5FAJMF6WQSG&currency_code=USD&source=url">
      <img src="https://img.shields.io/badge/Donate-PayPal-green.svg" alt="Donate to the founder" />
    </a>
  </p>
  <p>
    <h1>
      Archival Spider
    </h1>
    <h4>Efficient means to documenting your projects info.</h4>
  </p>
  <p>
    <a href="https://github.com/netrules/archival-web-spider">
      <img src="https://img.shields.io/badge/python-experimental-orange.svg?style=flat" alt="Educational/Experimental project" />
    </a>
    <a href="https://travis-ci.com/netrules/archival-web-spider">
      <img src="https://travis-ci.com/netrules/archival-web-spider.svg?branch=master" alt="Compliant with TravisCI standard" />
    </a>
    <a href="https://github.com/netrules/archival-web-spider/actions">
      <img src="https://github.com/netrules/archival-web-spider/workflows/Python%20application/badge.svg" alt="Compliant with Python Application standard" />
    </a>
    <a href="https://github.com/netrules/archival-web-spider/issues">
      <img src="https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat" alt="Contribute to the repo" />
    </a>
    <a href="https://codeclimate.com/github/netrules/archival-web-spider">
      <img src="https://codeclimate.com/github/netrules/archival-web-spider/badges/gpa.svg" alt="Codeclimate quality" />
    </a>
    <a href="https://snyk.io/test/github/netrules/archival-web-spider">
      <img src="https://snyk.io/test/github/netrules/archival-web-spider/badge.svg" alt="Vulnerabilities" />
    </a>
    <a href="https://codecov.io/gh/netrules/archival-web-spider">
      <img src="https://codecov.io/gh/netrules/archival-web-spider/branch/master/graph/badge.svg" alt="Code coverage" />
    </a>
    <a href="https://hits.dwyl.com/netrules/archival-web-spider">
      <img src="https://hits.dwyl.com/netrules/archival-web-spider.svg" alt="HitCount" />
    </a>
  </p>
</div>
	
## Inspired By
Project inspired by the likes of archive.org and miscellaneous free archival and curation projects. Intended to work for a broader public with a larger objective.

## About
Python project which uses mainly BeautifulSoup and Selenium Webdriver in order to crawl through websites and retrieve their resources in order to keep a personal record of documentation studied. Not meant to be used without webmasters permissions; this is only for learning purposes. [We do not encourage you to breach terms of any website.](https://towardsdatascience.com/web-scraping-with-python-a-to-copy-z-277a445d64c7)

## To-do
- Included files within script should be able to:
	- Follow principles of deduplication based filesystem such as: [Duplicacy - Cloud Backup Tool](https://duplicacy.com/), [Borg - Deduplicating Archiver](https://github.com/borgbackup/borg), [SDFS - Deduplicating FS](https://github.com/opendedup/sdfs)
	- Permit elastic mapping as external scripts continue to be stored in CDN for using network bandwidth instead
	- Inline styles by using [Pynliner - CSS-to-inline-styles conversion tool](https://github.com/rennat/pynliner)
- Can follow principles of mind mapping and memory techniques, such as:
	- [Learn Anything](https://learn-anything.xyz/#!)
	- [Anki Flash Cards](https://apps.ankiweb.net/)
- Make decentralization possible due to browsing websites offline, saved per domain
- Add as pip package

## Donate
Donate if you can spare a few bucks for pizza, coffee or just general sustenance. I appreciate it.

[![Donate Button](https://www.paypalobjects.com/en_US/i/btn/btn_donateCC_LG.gif)](https://www.paypal.com/cgi-bin/webscr?cmd=_donations&business=NF5FAJMF6WQSG&currency_code=USD&source=url)
